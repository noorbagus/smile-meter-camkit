// src/hooks/useCameraKit.ts - Complete adaptive resolution implementation
import { useState, useRef, useCallback, useEffect } from 'react';
import { bootstrapCameraKit, createMediaStreamSource, Transform2D } from '@snap/camera-kit';
import { createAdaptiveCameraKitConfig, validateConfig } from '../config/cameraKit';
import type { CameraState } from './useCameraPermissions';

// Singleton Camera Kit instance
let cameraKitInstance: any = null;
let preloadPromise: Promise<any> | null = null;

const withTimeout = <T>(promise: Promise<T>, ms: number): Promise<T> => {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) => 
      setTimeout(() => reject(new Error(`Timeout after ${ms}ms`)), ms)
    )
  ]);
};

const preloadCameraKit = async () => {
  if (cameraKitInstance) return cameraKitInstance;
  if (preloadPromise) return preloadPromise;
  
  preloadPromise = (async () => {
    try {
      if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
        throw new Error('HTTPS_REQUIRED');
      }
      
      validateConfig();
      cameraKitInstance = await bootstrapCameraKit({ 
        apiToken: import.meta.env.VITE_CAMERA_KIT_API_TOKEN || 'eyJhbGciOiJIUzI1NiIsImtpZCI6IkNhbnZhc1MyU0hNQUNQcm9kIiwidHlwIjoiSldUIn0.eyJhdWQiOiJjYW52YXMtY2FudmFzYXBpIiwiaXNzIjoiY2FudmFzLXMyc3Rva2VuIiwibmJmIjoxNzQ3MDM1OTAyLCJzdWIiOiI2YzMzMWRmYy0zNzEzLTQwYjYtYTNmNi0zOTc2OTU3ZTkyZGF-UFJPRFVDVElPTn5jZjM3ZDAwNy1iY2IyLTQ3YjEtODM2My1jYWIzYzliOGJhM2YifQ.UqGhWZNuWXplirojsPSgZcsO3yu98WkTM1MRG66dsHI'
      });
      
      return cameraKitInstance;
    } catch (error) {
      cameraKitInstance = null;
      preloadPromise = null;
      throw error;
    }
  })();
  
  return preloadPromise;
};

// Start preloading
preloadCameraKit().catch(console.error);

export const useCameraKit = (addLog: (message: string) => void) => {
  const [cameraState, setCameraState] = useState<CameraState>('initializing');
  const [currentFacingMode, setCurrentFacingMode] = useState<'user' | 'environment'>('user');
  
  const sessionRef = useRef<any>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const outputCanvasRef = useRef<HTMLCanvasElement | null>(null);
  const lensRepositoryRef = useRef<any>(null);
  const isAttachedRef = useRef<boolean>(false);
  const containerRef = useRef<React.RefObject<HTMLDivElement> | null>(null);
  const isInitializedRef = useRef<boolean>(false);
  const currentConfigRef = useRef<any>(null);

  // Adaptive canvas attachment with perfect scaling
  const attachCameraOutputAdaptive = useCallback((
    canvas: HTMLCanvasElement, 
    containerReference: React.RefObject<HTMLDivElement>,
    config: any
  ) => {
    if (!containerReference.current) {
      addLog('‚ùå Camera feed container not available');
      return;
    }

    try {
      requestAnimationFrame(() => {
        if (!containerReference.current) return;

        // Clear container
        while (containerReference.current.firstChild) {
          try {
            containerReference.current.removeChild(containerReference.current.firstChild);
          } catch (e) {
            break;
          }
        }
        
        outputCanvasRef.current = canvas;
        
        addLog(`üìä Adaptive Canvas: ${canvas.width}x${canvas.height}`);
        
        // Get container dimensions for perfect fit
        const containerRect = containerReference.current.getBoundingClientRect();
        const canvasAspect = canvas.width / canvas.height;
        const containerAspect = containerRect.width / containerRect.height;
        
        // Calculate optimal fit to prevent upscaling
        let displayWidth, displayHeight;
        if (canvasAspect > containerAspect) {
          // Canvas wider - fit to width
          displayWidth = containerRect.width;
          displayHeight = containerRect.width / canvasAspect;
        } else {
          // Canvas taller - fit to height
          displayHeight = containerRect.height;
          displayWidth = containerRect.height * canvasAspect;
        }
        
        // Perfect fit CSS - no pixelation
        canvas.style.cssText = `
          position: absolute;
          top: 50%;
          left: 50%;
          width: ${displayWidth}px;
          height: ${displayHeight}px;
          transform: translate(-50%, -50%);
          object-fit: contain;
          object-position: center;
          background: transparent;
          image-rendering: crisp-edges;
          will-change: transform;
          backface-visibility: hidden;
        `;
        
        // Container styling
        const container = containerReference.current;
        container.style.cssText = `
          position: relative;
          width: 100%;
          height: 100%;
          overflow: hidden;
          display: flex;
          align-items: center;
          justify-content: center;
          background: #000;
          touch-action: manipulation;
        `;
        
        try {
          container.appendChild(canvas);
          isAttachedRef.current = true;
          
          const scaleX = displayWidth / canvas.width;
          const scaleY = displayHeight / canvas.height;
          addLog(`‚úÖ Adaptive canvas attached - Scale: ${scaleX.toFixed(3)}x${scaleY.toFixed(3)}`);
        } catch (e) {
          addLog(`‚ùå Canvas attachment failed: ${e}`);
        }
      });
    } catch (error) {
      addLog(`‚ùå Adaptive canvas attachment error: ${error}`);
    }
  }, [addLog]);

  const restoreCameraFeed = useCallback(() => {
    if (sessionRef.current && outputCanvasRef.current && containerRef.current?.current) {
      addLog('üîÑ Restoring camera feed...');
      
      const isCanvasAttached = containerRef.current.current.contains(outputCanvasRef.current);
      
      if (!isCanvasAttached && currentConfigRef.current) {
        addLog('üì± Re-attaching adaptive canvas');
        attachCameraOutputAdaptive(outputCanvasRef.current, containerRef.current, currentConfigRef.current);
      }
      
      if (sessionRef.current.output?.live) {
        try {
          sessionRef.current.play('live');
          addLog('‚ñ∂Ô∏è Session resumed');
        } catch (error) {
          addLog(`‚ö†Ô∏è Resume error: ${error}`);
        }
      }
    }
  }, [addLog, attachCameraOutputAdaptive]);

  const reloadLens = useCallback(async (): Promise<boolean> => {
    if (!sessionRef.current || !isInitializedRef.current) {
      addLog('‚ùå Cannot reload - session not ready');
      return false;
    }

    try {
      addLog('üîÑ Restarting AR lens...');
      
      sessionRef.current.pause();
      await new Promise(resolve => setTimeout(resolve, 200));
      
      try {
        await withTimeout(sessionRef.current.removeLens(), 2000);
        addLog('üóëÔ∏è Lens removed');
      } catch (removeError) {
        addLog(`‚ö†Ô∏è Lens removal failed: ${removeError}`);
      }
      
      await new Promise(resolve => setTimeout(resolve, 300));
      
      const lenses = lensRepositoryRef.current;
      if (lenses && lenses.length > 0 && currentConfigRef.current) {
        const targetLens = lenses.find((lens: any) => lens.id === currentConfigRef.current.lensId) || lenses[0];
        await withTimeout(sessionRef.current.applyLens(targetLens), 3000);
        addLog(`‚úÖ Lens restarted: ${targetLens.name}`);
      }
      
      sessionRef.current.play('live');
      
      setTimeout(() => {
        restoreCameraFeed();
      }, 300);
      
      addLog('üéâ AR lens restarted');
      return true;
      
    } catch (error) {
      addLog(`‚ùå Lens restart failed: ${error}`);
      
      try {
        sessionRef.current.play('live');
      } catch (recoveryError) {
        addLog(`‚ùå Recovery failed: ${recoveryError}`);
      }
      
      return false;
    }
  }, [addLog, restoreCameraFeed]);

  // Visibility change handler
  useEffect(() => {
    const handleVisibilityChange = () => {
      if (document.visibilityState === 'visible') {
        addLog('üëÅÔ∏è App visible - checking camera...');
        setTimeout(() => {
          restoreCameraFeed();
        }, 100);
      }
    };

    document.addEventListener('visibilitychange', handleVisibilityChange);
    
    return () => {
      document.removeEventListener('visibilitychange', handleVisibilityChange);
    };
  }, [addLog, restoreCameraFeed]);

  const initializeCameraKit = useCallback(async (
    stream: MediaStream,
    containerReference: React.RefObject<HTMLDivElement>
  ): Promise<boolean> => {
    try {
      // Create adaptive config based on container
      const adaptiveConfig = createAdaptiveCameraKitConfig(containerReference);
      currentConfigRef.current = adaptiveConfig;
      
      // Re-initialization check
      if (isInitializedRef.current && sessionRef.current && cameraState === 'ready') {
        addLog('üì± Updating existing session with adaptive config...');
        
        const source = createMediaStreamSource(stream, {
          transform: currentFacingMode === 'user' ? Transform2D.MirrorX : undefined,
          cameraType: currentFacingMode
        });
        
        await withTimeout(sessionRef.current.setSource(source), 3000);
        
        // Apply adaptive render size
        await source.setRenderSize(adaptiveConfig.canvas.width, adaptiveConfig.canvas.height);
        addLog(`‚úÖ Adaptive render: ${adaptiveConfig.canvas.width}x${adaptiveConfig.canvas.height}`);
        
        streamRef.current = stream;
        containerRef.current = containerReference;
        
        if (sessionRef.current.output?.live && containerReference.current && !isAttachedRef.current) {
          setTimeout(() => {
            if (sessionRef.current.output.live) {
              attachCameraOutputAdaptive(sessionRef.current.output.live, containerReference, adaptiveConfig);
            }
          }, 100);
        }
        
        addLog('‚úÖ Adaptive stream updated');
        return true;
      }

      addLog('üé≠ Initializing Camera Kit with adaptive resolution...');
      addLog(`üìê Adaptive canvas: ${adaptiveConfig.canvas.width}x${adaptiveConfig.canvas.height}`);
      setCameraState('initializing');
      containerRef.current = containerReference;

      // Bootstrap Camera Kit
      let cameraKit = cameraKitInstance;
      if (!cameraKit) {
        addLog('Bootstrapping Camera Kit...');
        try {
          cameraKit = await withTimeout(preloadCameraKit(), 10000);
        } catch (ckError: any) {
          addLog(`‚ùå Bootstrap failed: ${ckError.message}`);
          setCameraState('error');
          return false;
        }
      }
      
      if (!cameraKit) {
        throw new Error('Failed to initialize Camera Kit');
      }

      addLog('üé¨ Creating adaptive session...');
      const session: any = await withTimeout(cameraKit.createSession(), 5000);
      sessionRef.current = session;
      streamRef.current = stream;
      isInitializedRef.current = true;
      
      session.events.addEventListener("error", (event: any) => {
        addLog(`‚ùå Session error: ${event.detail}`);
        setCameraState('error');
      });

      // Create source
      const source = createMediaStreamSource(stream, {
        transform: currentFacingMode === 'user' ? Transform2D.MirrorX : undefined,
        cameraType: currentFacingMode
      });
      
      await withTimeout(session.setSource(source), 3000);
      addLog('‚úÖ Camera source configured');

      // Set adaptive render size
      await source.setRenderSize(adaptiveConfig.canvas.width, adaptiveConfig.canvas.height);
      addLog(`‚úÖ Adaptive AR render: ${adaptiveConfig.canvas.width}x${adaptiveConfig.canvas.height}`);

      // Load lens repository
      if (!lensRepositoryRef.current) {
        try {
          const lensResult: any = await withTimeout(
            cameraKit.lensRepository.loadLensGroups([adaptiveConfig.lensGroupId]), 
            5000
          );
          lensRepositoryRef.current = lensResult.lenses;
          addLog('‚úÖ Lens repository loaded');
        } catch (lensError) {
          addLog(`‚ö†Ô∏è Lens loading failed: ${lensError}`);
        }
      }

      // Apply lens
      const lenses = lensRepositoryRef.current;
      if (lenses && lenses.length > 0) {
        try {
          const targetLens = lenses.find((lens: any) => lens.id === adaptiveConfig.lensId) || lenses[0];
          await withTimeout(session.applyLens(targetLens), 3000);
          addLog(`‚úÖ Lens applied: ${targetLens.name}`);
        } catch (lensApplyError) {
          addLog(`‚ö†Ô∏è Lens application failed: ${lensApplyError}`);
        }
      }

      // Start session
      session.play('live');

      // Attach adaptive output
      setTimeout(() => {
        if (session.output.live && containerReference.current && !isAttachedRef.current) {
          addLog('üé• Attaching adaptive Camera Kit output...');
          attachCameraOutputAdaptive(session.output.live, containerReference, adaptiveConfig);
        }
      }, 500);

      setCameraState('ready');
      addLog('üéâ Adaptive Camera Kit initialization complete');
      return true;

    } catch (error: any) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      addLog(`‚ùå Camera Kit error: ${errorMessage}`);
      setCameraState('error');
      return false;
    }
  }, [currentFacingMode, addLog, attachCameraOutputAdaptive, cameraState]);

  const switchCamera = useCallback(async (): Promise<MediaStream | null> => {
    if (!sessionRef.current || !isInitializedRef.current) {
      addLog('‚ùå Cannot switch - session not initialized');
      return null;
    }

    try {
      const newFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
      addLog(`üîÑ Switching to ${newFacingMode} camera...`);

      // Pause session
      if (sessionRef.current.output?.live) {
        sessionRef.current.pause();
        addLog('‚è∏Ô∏è Session paused');
      }

      // Stop current stream
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => {
          track.stop();
          addLog(`üõë Stopped ${track.kind} track`);
        });
        streamRef.current = null;
      }

      await new Promise(resolve => setTimeout(resolve, 200));

      // Get new stream
      const newStream = await withTimeout(
        navigator.mediaDevices.getUserMedia({
          video: { 
            facingMode: newFacingMode,
            width: { ideal: 2560, min: 720 },
            height: { ideal: 1440, min: 480 },
            frameRate: { ideal: 30 }
          },
          audio: true
        }),
        5000
      );

      addLog(`‚úÖ New ${newFacingMode} stream obtained`);
      streamRef.current = newStream;

      // Set source with adaptive config
      const source = createMediaStreamSource(newStream, {
        transform: newFacingMode === 'user' ? Transform2D.MirrorX : undefined,
        cameraType: newFacingMode
      });
      
      await withTimeout(sessionRef.current.setSource(source), 3000);
      addLog('‚úÖ Source set');

      // Apply adaptive render size
      const config = currentConfigRef.current;
      if (config) {
        await source.setRenderSize(config.canvas.width, config.canvas.height);
        addLog(`‚úÖ Adaptive render: ${config.canvas.width}x${config.canvas.height}`);
      }

      await new Promise(resolve => setTimeout(resolve, 300));

      // Resume session
      if (sessionRef.current.output?.live) {
        sessionRef.current.play('live');
        addLog('‚ñ∂Ô∏è Session resumed');
      }

      setCurrentFacingMode(newFacingMode);
      addLog(`üéâ Camera switched to ${newFacingMode}`);
      return newStream;
      
    } catch (error: any) {
      addLog(`‚ùå Camera switch failed: ${error.message}`);
      
      try {
        if (sessionRef.current.output?.live) {
          sessionRef.current.play('live');
        }
        addLog('üîÑ Restored previous state');
      } catch (recoveryError) {
        addLog(`‚ùå Recovery failed: ${recoveryError}`);
        setCameraState('error');
      }
      
      return null;
    }
  }, [currentFacingMode, addLog]);

  const pauseSession = useCallback(() => {
    if (sessionRef.current) {
      sessionRef.current.pause();
      addLog('‚è∏Ô∏è Session paused');
    }
  }, [addLog]);

  const resumeSession = useCallback(() => {
    if (sessionRef.current) {
      sessionRef.current.play('live');
      addLog('‚ñ∂Ô∏è Session resumed');
    }
  }, [addLog]);

  const cleanup = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      addLog('üîÑ Stream stopped');
    }
    if (sessionRef.current) {
      sessionRef.current.pause();
      addLog('‚è∏Ô∏è Session paused');
    }
    isAttachedRef.current = false;
    containerRef.current = null;
    currentConfigRef.current = null;
  }, [addLog]);

  const getCanvas = useCallback(() => {
    return outputCanvasRef.current;
  }, []);

  const getStream = useCallback(() => {
    return streamRef.current;
  }, []);

  return {
    cameraState,
    currentFacingMode,
    initializeCameraKit,
    switchCamera,
    reloadLens,
    pauseSession,
    resumeSession,
    cleanup,
    getCanvas,
    getStream,
    restoreCameraFeed,
    isReady: cameraState === 'ready',
    isInitializing: cameraState === 'initializing'
  };
};